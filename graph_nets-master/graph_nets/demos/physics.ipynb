{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "k2QMetc6kava"
   },
   "outputs": [],
   "source": [
    "#@title ##### License\n",
    "# Copyright 2018 The GraphNets Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5CPvyHM2CnU"
   },
   "source": [
    "# Physical dynamics of a mass-spring system\n",
    "This notebook and the accompanying code demonstrates how to use the Graph Nets library to learn to predict the motion of a set of masses connected by springs.\n",
    "\n",
    "The network is trained to predict the behaviour of a chain of five masses, connected by identical springs. The first and last masses are fixed; the others are subject to gravity.\n",
    "\n",
    "After training, the network's prediction ability is illustrated by comparing its output to the true behaviour of the structure. Then the network's ability to generalise is tested, by using it to predict the behaviour of a similar but more complicated mass/spring structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Ss54UNGvkz5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping installation of Graph Nets library\n"
     ]
    }
   ],
   "source": [
    "#@title ### Install the Graph Nets library on this Colaboratory runtime  { form-width: \"60%\", run: \"auto\"}\n",
    "#@markdown <br>1. Connect to a local or hosted Colaboratory runtime by clicking the **Connect** button at the top-right.<br>2. Choose \"Yes\" below to install the Graph Nets library on the runtime machine with:<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;```pip install graph_nets```<br> Note, this works both with local and hosted Colaboratory runtimes.\n",
    "\n",
    "install_graph_nets_library = \"No\"  #@param [\"Yes\", \"No\"]\n",
    "\n",
    "if install_graph_nets_library.lower() == \"yes\":\n",
    "  print(\"Installing Graph Nets library with:\")\n",
    "  print(\"  $ pip install graph_nets\\n\")\n",
    "  print(\"Output message from command:\\n\")\n",
    "  !pip install graph_nets\n",
    "else:\n",
    "  print(\"Skipping installation of Graph Nets library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7E4elJkXFR4a"
   },
   "source": [
    "### Install dependencies locally\n",
    "\n",
    "If you are running this notebook locally (i.e., not through Colaboratory), you will also need to install a few more dependencies. Run the following on the command line to install the graph networks library, as well as a few other dependencies:\n",
    "\n",
    "```\n",
    "pip install graph_nets matplotlib scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyVaNA-bGug3"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RzKvtoAgRA8e"
   },
   "outputs": [],
   "source": [
    "#@title Imports  { form-width: \"30%\" }\n",
    "\n",
    "# The demo dependencies are not installed with the library, but you can install\n",
    "# them with:\n",
    "#\n",
    "# $ pip install jupyter matplotlib scipy\n",
    "#\n",
    "# Run the demo with:\n",
    "#\n",
    "# $ jupyter notebook <path>/<to>/<demos>/shortest_path.ipynb\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "from graph_nets import blocks\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets.demos import models\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "  import seaborn as sns\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  sns.reset_orig()\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "toCQhJIM93en"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions  { form-width: \"30%\" }\n",
    "\n",
    "# pylint: disable=redefined-outer-name\n",
    "\n",
    "def base_graph(n, d):\n",
    "  \"\"\"Define a basic mass-spring system graph structure.\n",
    "\n",
    "  These are n masses (1kg) connected by springs in a chain-like structure. The\n",
    "  first and last masses are fixed. The masses are vertically aligned at the\n",
    "  start and are d meters apart; this is also the rest length for the springs\n",
    "  connecting them. Springs have spring constant 50 N/m and gravity is 10 N in\n",
    "  the negative y-direction.\n",
    "\n",
    "  Args:\n",
    "    n: number of masses\n",
    "    d: distance between masses (as well as springs' rest length)\n",
    "\n",
    "  Returns:\n",
    "    data_dict: dictionary with globals, nodes, edges, receivers and senders\n",
    "        to represent a structure like the one above.\n",
    "  \"\"\"\n",
    "  # Nodes\n",
    "  # Generate initial position and velocity for all masses.\n",
    "  # The left-most mass has is at position (0, 0); other masses (ordered left to\n",
    "  # right) have x-coordinate d meters apart from their left neighbor, and\n",
    "  # y-coordinate 0. All masses have initial velocity 0m/s.\n",
    "  nodes = np.zeros((n, 5), dtype=np.float32)\n",
    "  half_width = d * n / 2.0\n",
    "  nodes[:, 0] = np.linspace(\n",
    "      -half_width, half_width, num=n, endpoint=False, dtype=np.float32)\n",
    "  # indicate that the first and last masses are fixed\n",
    "  nodes[(0, -1), -1] = 1.\n",
    "\n",
    "  # Edges.\n",
    "  edges, senders, receivers = [], [], []\n",
    "  for i in range(n - 1):\n",
    "    left_node = i\n",
    "    right_node = i + 1\n",
    "    # The 'if' statements prevent incoming edges to fixed ends of the string.\n",
    "    if right_node < n - 1:\n",
    "      # Left incoming edge.\n",
    "      edges.append([50., d])\n",
    "      senders.append(left_node)\n",
    "      receivers.append(right_node)\n",
    "    if left_node > 0:\n",
    "      # Right incoming edge.\n",
    "      edges.append([50., d])\n",
    "      senders.append(right_node)\n",
    "      receivers.append(left_node)\n",
    "\n",
    "  return {\n",
    "      \"globals\": [0., -10.],\n",
    "      \"nodes\": nodes,\n",
    "      \"edges\": edges,\n",
    "      \"receivers\": receivers,\n",
    "      \"senders\": senders\n",
    "  }\n",
    "\n",
    "\n",
    "def hookes_law(receiver_nodes, sender_nodes, k, x_rest):\n",
    "  \"\"\"Applies Hooke's law to springs connecting some nodes.\n",
    "\n",
    "  Args:\n",
    "    receiver_nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for the\n",
    "      receiver node of each edge.\n",
    "    sender_nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for the\n",
    "      sender node of each edge.\n",
    "    k: Spring constant for each edge.\n",
    "    x_rest: Rest length of each edge.\n",
    "\n",
    "  Returns:\n",
    "    Nx2 Tensor of the force [f_x, f_y] acting on each edge.\n",
    "  \"\"\"\n",
    "  diff = receiver_nodes[..., 0:2] - sender_nodes[..., 0:2]\n",
    "  x = tf.norm(diff, axis=-1, keepdims=True)\n",
    "  force_magnitude = -1 * tf.multiply(k, (x - x_rest) / x)\n",
    "  force = force_magnitude * diff\n",
    "  return force\n",
    "\n",
    "\n",
    "def euler_integration(nodes, force_per_node, step_size):\n",
    "  \"\"\"Applies one step of Euler integration.\n",
    "\n",
    "  Args:\n",
    "    nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each node.\n",
    "    force_per_node: Ex2 tf.Tensor of the force [f_x, f_y] acting on each edge.\n",
    "    step_size: Scalar.\n",
    "\n",
    "  Returns:\n",
    "    A tf.Tensor of the same shape as `nodes` but with positions and velocities\n",
    "        updated.\n",
    "  \"\"\"\n",
    "  is_fixed = nodes[..., 4:5]\n",
    "  # set forces to zero for fixed nodes\n",
    "  force_per_node *= 1 - is_fixed\n",
    "  new_vel = nodes[..., 2:4] + force_per_node * step_size\n",
    "  return new_vel\n",
    "\n",
    "\n",
    "class SpringMassSimulator(snt.AbstractModule):\n",
    "  \"\"\"Implements a basic Physics Simulator using the blocks library.\"\"\"\n",
    "\n",
    "  def __init__(self, step_size, name=\"SpringMassSimulator\"):\n",
    "    super(SpringMassSimulator, self).__init__(name=name)\n",
    "    self._step_size = step_size\n",
    "\n",
    "    with self._enter_variable_scope():\n",
    "      self._aggregator = blocks.ReceivedEdgesToNodesAggregator(\n",
    "          reducer=tf.unsorted_segment_sum)\n",
    "\n",
    "  def _build(self, graph):\n",
    "    \"\"\"Builds a SpringMassSimulator.\n",
    "\n",
    "    Args:\n",
    "      graph: A graphs.GraphsTuple having, for some integers N, E, G:\n",
    "          - edges: Nx2 tf.Tensor of [spring_constant, rest_length] for each\n",
    "            edge.\n",
    "          - nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each\n",
    "            node.\n",
    "          - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
    "\n",
    "    Returns:\n",
    "      A graphs.GraphsTuple of the same shape as `graph`, but where:\n",
    "          - edges: Holds the force [f_x, f_y] acting on each edge.\n",
    "          - nodes: Holds positions and velocities after applying one step of\n",
    "              Euler integration.\n",
    "    \"\"\"\n",
    "    receiver_nodes = blocks.broadcast_receiver_nodes_to_edges(graph)\n",
    "    sender_nodes = blocks.broadcast_sender_nodes_to_edges(graph)\n",
    "\n",
    "    spring_force_per_edge = hookes_law(receiver_nodes, sender_nodes,\n",
    "                                       graph.edges[..., 0:1],\n",
    "                                       graph.edges[..., 1:2])\n",
    "    graph = graph.replace(edges=spring_force_per_edge)\n",
    "\n",
    "    spring_force_per_node = self._aggregator(graph)\n",
    "    gravity = blocks.broadcast_globals_to_nodes(graph)\n",
    "    updated_velocities = euler_integration(\n",
    "        graph.nodes, spring_force_per_node + gravity, self._step_size)\n",
    "    graph = graph.replace(nodes=updated_velocities)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def prediction_to_next_state(input_graph, predicted_graph, step_size):\n",
    "  # manually integrate velocities to compute new positions\n",
    "  new_pos = input_graph.nodes[..., :2] + predicted_graph.nodes * step_size\n",
    "  new_nodes = tf.concat(\n",
    "      [new_pos, predicted_graph.nodes, input_graph.nodes[..., 4:5]], axis=-1)\n",
    "  return input_graph.replace(nodes=new_nodes)\n",
    "\n",
    "\n",
    "def roll_out_physics(simulator, graph, steps, step_size):\n",
    "  \"\"\"Apply some number of steps of physical laws to an interaction network.\n",
    "\n",
    "  Args:\n",
    "    simulator: A SpringMassSimulator, or some module or callable with the same\n",
    "      signature.\n",
    "    graph: A graphs.GraphsTuple having, for some integers N, E, G:\n",
    "        - edges: Nx2 tf.Tensor of [spring_constant, rest_length] for each edge.\n",
    "        - nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each\n",
    "          node.\n",
    "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
    "    steps: An integer.\n",
    "    step_size: Scalar.\n",
    "\n",
    "  Returns:\n",
    "    A pair of:\n",
    "    - The graph, updated after `steps` steps of simulation;\n",
    "    - A `steps+1`xNx5 tf.Tensor of the node features at each step.\n",
    "  \"\"\"\n",
    "\n",
    "  def body(t, graph, nodes_per_step):\n",
    "    predicted_graph = simulator(graph)\n",
    "    if isinstance(predicted_graph, list):\n",
    "      predicted_graph = predicted_graph[-1]\n",
    "    graph = prediction_to_next_state(graph, predicted_graph, step_size)\n",
    "    return t + 1, graph, nodes_per_step.write(t, graph.nodes)\n",
    "\n",
    "  nodes_per_step = tf.TensorArray(\n",
    "      dtype=graph.nodes.dtype, size=steps + 1, element_shape=graph.nodes.shape)\n",
    "  nodes_per_step = nodes_per_step.write(0, graph.nodes)\n",
    "\n",
    "  _, g, nodes_per_step = tf.while_loop(\n",
    "      lambda t, *unused_args: t <= steps,\n",
    "      body,\n",
    "      loop_vars=[1, graph, nodes_per_step])\n",
    "  return g, nodes_per_step.stack()\n",
    "\n",
    "\n",
    "def apply_noise(graph, node_noise_level, edge_noise_level, global_noise_level):\n",
    "  \"\"\"Applies uniformly-distributed noise to a graph of a physical system.\n",
    "\n",
    "  Noise is applied to:\n",
    "  - the x and y coordinates (independently) of the nodes;\n",
    "  - the spring constants of the edges;\n",
    "  - the y coordinate of the global gravitational constant.\n",
    "\n",
    "  Args:\n",
    "    graph: a graphs.GraphsTuple having, for some integers N, E, G:\n",
    "        - nodes: Nx5 Tensor of [x, y, _, _, _] for each node.\n",
    "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
    "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
    "    node_noise_level: Maximum distance to perturb nodes' x and y coordinates.\n",
    "    edge_noise_level: Maximum amount to perturb edge spring constants.\n",
    "    global_noise_level: Maximum amount to perturb the Y component of gravity.\n",
    "\n",
    "  Returns:\n",
    "    The input graph, but with noise applied.\n",
    "  \"\"\"\n",
    "  node_position_noise = tf.random_uniform(\n",
    "      [graph.nodes.shape[0].value, 2],\n",
    "      minval=-node_noise_level,\n",
    "      maxval=node_noise_level)\n",
    "  edge_spring_constant_noise = tf.random_uniform(\n",
    "      [graph.edges.shape[0].value, 1],\n",
    "      minval=-edge_noise_level,\n",
    "      maxval=edge_noise_level)\n",
    "  global_gravity_y_noise = tf.random_uniform(\n",
    "      [graph.globals.shape[0].value, 1],\n",
    "      minval=-global_noise_level,\n",
    "      maxval=global_noise_level)\n",
    "\n",
    "  return graph.replace(\n",
    "      nodes=tf.concat(\n",
    "          [graph.nodes[..., :2] + node_position_noise, graph.nodes[..., 2:]],\n",
    "          axis=-1),\n",
    "      edges=tf.concat(\n",
    "          [\n",
    "              graph.edges[..., :1] + edge_spring_constant_noise,\n",
    "              graph.edges[..., 1:]\n",
    "          ],\n",
    "          axis=-1),\n",
    "      globals=tf.concat(\n",
    "          [\n",
    "              graph.globals[..., :1],\n",
    "              graph.globals[..., 1:] + global_gravity_y_noise\n",
    "          ],\n",
    "          axis=-1))\n",
    "\n",
    "\n",
    "def set_rest_lengths(graph):\n",
    "  \"\"\"Computes and sets rest lengths for the springs in a physical system.\n",
    "\n",
    "  The rest length is taken to be the distance between each edge's nodes.\n",
    "\n",
    "  Args:\n",
    "    graph: a graphs.GraphsTuple having, for some integers N, E:\n",
    "        - nodes: Nx5 Tensor of [x, y, _, _, _] for each node.\n",
    "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
    "\n",
    "  Returns:\n",
    "    The input graph, but with [spring_constant, rest_length] for each edge.\n",
    "  \"\"\"\n",
    "  receiver_nodes = blocks.broadcast_receiver_nodes_to_edges(graph)\n",
    "  sender_nodes = blocks.broadcast_sender_nodes_to_edges(graph)\n",
    "  rest_length = tf.norm(\n",
    "      receiver_nodes[..., :2] - sender_nodes[..., :2], axis=-1, keepdims=True)\n",
    "  return graph.replace(\n",
    "      edges=tf.concat([graph.edges[..., :1], rest_length], axis=-1))\n",
    "\n",
    "\n",
    "def generate_trajectory(simulator, graph, steps, step_size, node_noise_level,\n",
    "                        edge_noise_level, global_noise_level):\n",
    "  \"\"\"Applies noise and then simulates a physical system for a number of steps.\n",
    "\n",
    "  Args:\n",
    "    simulator: A SpringMassSimulator, or some module or callable with the same\n",
    "      signature.\n",
    "    graph: a graphs.GraphsTuple having, for some integers N, E, G:\n",
    "        - nodes: Nx5 Tensor of [x, y, v_x, v_y, is_fixed] for each node.\n",
    "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
    "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
    "    steps: Integer; the length of trajectory to generate.\n",
    "    step_size: Scalar.\n",
    "    node_noise_level: Maximum distance to perturb nodes' x and y coordinates.\n",
    "    edge_noise_level: Maximum amount to perturb edge spring constants.\n",
    "    global_noise_level: Maximum amount to perturb the Y component of gravity.\n",
    "\n",
    "  Returns:\n",
    "    A pair of:\n",
    "    - The input graph, but with rest lengths computed and noise applied.\n",
    "    - A `steps+1`xNx5 tf.Tensor of the node features at each step.\n",
    "  \"\"\"\n",
    "  graph = apply_noise(graph, node_noise_level, edge_noise_level,\n",
    "                      global_noise_level)\n",
    "  graph = set_rest_lengths(graph)\n",
    "  _, n = roll_out_physics(simulator, graph, steps, step_size)\n",
    "  return graph, n\n",
    "\n",
    "\n",
    "def create_loss_ops(target_op, output_ops):\n",
    "  \"\"\"Create supervised loss operations from targets and outputs.\n",
    "\n",
    "  Args:\n",
    "    target_op: The target velocity tf.Tensor.\n",
    "    output_ops: The list of output graphs from the model.\n",
    "\n",
    "  Returns:\n",
    "    A list of loss values (tf.Tensor), one per output op.\n",
    "  \"\"\"\n",
    "  loss_ops = [\n",
    "      tf.reduce_mean(\n",
    "          tf.reduce_sum((output_op.nodes - target_op[..., 2:4])**2, axis=-1))\n",
    "      for output_op in output_ops\n",
    "  ]\n",
    "  return loss_ops\n",
    "\n",
    "\n",
    "def make_all_runnable_in_session(*args):\n",
    "  \"\"\"Apply make_runnable_in_session to an iterable of graphs.\"\"\"\n",
    "  return [utils_tf.make_runnable_in_session(a) for a in args]\n",
    "\n",
    "\n",
    "# pylint: enable=redefined-outer-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "pf7u0zuN_ktd"
   },
   "outputs": [],
   "source": [
    "#@title Set up model training and evaluation  { form-width: \"30%\" }\n",
    "\n",
    "# The model we explore includes three components:\n",
    "# - An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
    "#   global attributes (does not compute relations etc.).\n",
    "# - A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
    "#   steps. The input to the Core is the concatenation of the Encoder's output\n",
    "#   and the previous output of the Core (labeled \"Hidden(t)\" below, where \"t\" is\n",
    "#   the processing step).\n",
    "# - A \"Decoder\" graph net, which independently decodes the edge, node, and\n",
    "#   global attributes (does not compute relations etc.), on each\n",
    "#   message-passing step.\n",
    "#\n",
    "#                     Hidden(t)   Hidden(t+1)\n",
    "#                        |            ^\n",
    "#           *---------*  |  *------*  |  *---------*\n",
    "#           |         |  |  |      |  |  |         |\n",
    "# Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)\n",
    "#           |         |---->|      |     |         |\n",
    "#           *---------*     *------*     *---------*\n",
    "#\n",
    "# The model is trained by supervised learning. Input mass-spring systems are\n",
    "# procedurally generated, where the nodes represent the positions, velocities,\n",
    "# and indicators of whether the mass is fixed in space or free to move, the\n",
    "# edges represent the spring constant and spring rest length, and the global\n",
    "# attribute represents the variable coefficient of gravitational acceleration.\n",
    "# The outputs/targets have the same structure, with the nodes representing the\n",
    "# masses' next-step states.\n",
    "#\n",
    "# The training loss is computed on the output of each processing step. The\n",
    "# reason for this is to encourage the model to try to solve the problem in as\n",
    "# few steps as possible. It also helps make the output of intermediate steps\n",
    "# more interpretable.\n",
    "#\n",
    "# There's no need for a separate evaluate dataset because the inputs are\n",
    "# never repeated, so the training loss is the measure of performance on graphs\n",
    "# from the input distribution.\n",
    "#\n",
    "# We also evaluate how well the models generalize to systems which are one mass\n",
    "# larger, and smaller, than those from the training distribution. The loss is\n",
    "# computed as the mean over a 50-step rollout, where each step's input is the\n",
    "# the previous step's output.\n",
    "#\n",
    "# Variables with the suffix _tr are training parameters, and variables with the\n",
    "# suffix _ge are test/generalization parameters.\n",
    "#\n",
    "# After around 10000-20000 training iterations the model reaches good\n",
    "# performance on mass-spring systems with 5-8 masses.\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "rand = np.random.RandomState(SEED)\n",
    "\n",
    "# Model parameters.\n",
    "num_processing_steps_tr = 1\n",
    "num_processing_steps_ge = 1\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 100000\n",
    "batch_size_tr = 256\n",
    "batch_size_ge = 100\n",
    "num_time_steps = 50\n",
    "step_size = 0.1\n",
    "num_masses_min_max_tr = (5, 9)\n",
    "dist_between_masses_min_max_tr = (0.2, 1.0)\n",
    "\n",
    "# Create the model.\n",
    "model = models.EncodeProcessDecode(node_output_size=2)\n",
    "\n",
    "# Data.\n",
    "# Base graphs for training.\n",
    "num_masses_tr = rand.randint(*num_masses_min_max_tr, size=batch_size_tr)\n",
    "dist_between_masses_tr = rand.uniform(\n",
    "    *dist_between_masses_min_max_tr, size=batch_size_tr)\n",
    "static_graph_tr = [\n",
    "    base_graph(n, d) for n, d in zip(num_masses_tr, dist_between_masses_tr)\n",
    "]\n",
    "base_graph_tr = utils_tf.data_dicts_to_graphs_tuple(static_graph_tr)\n",
    "# Base graphs for testing.\n",
    "# 4 masses 1m apart in a chain like structure.\n",
    "base_graph_4_ge = utils_tf.data_dicts_to_graphs_tuple(\n",
    "    [base_graph(4, 0.5)] * batch_size_ge)\n",
    "# 9 masses 0.5m apart in a chain like structure.\n",
    "base_graph_9_ge = utils_tf.data_dicts_to_graphs_tuple(\n",
    "    [base_graph(9, 0.5)] * batch_size_ge)\n",
    "# True physics simulator for data generation.\n",
    "simulator = SpringMassSimulator(step_size=step_size)\n",
    "# Training.\n",
    "# Generate a training trajectory by adding noise to initial\n",
    "# position, spring constants and gravity\n",
    "initial_conditions_tr, true_trajectory_tr = generate_trajectory(\n",
    "    simulator,\n",
    "    base_graph_tr,\n",
    "    num_time_steps,\n",
    "    step_size,\n",
    "    node_noise_level=0.04,\n",
    "    edge_noise_level=5.0,\n",
    "    global_noise_level=1.0)\n",
    "# Random start step.\n",
    "t = tf.random_uniform([], minval=0, maxval=num_time_steps - 1, dtype=tf.int32)\n",
    "input_graph_tr = initial_conditions_tr.replace(nodes=true_trajectory_tr[t])\n",
    "target_nodes_tr = true_trajectory_tr[t + 1]\n",
    "output_ops_tr = model(input_graph_tr, num_processing_steps_tr)\n",
    "# Test data: 4-mass string.\n",
    "initial_conditions_4_ge, true_trajectory_4_ge = generate_trajectory(\n",
    "    lambda x: model(x, num_processing_steps_ge),\n",
    "    base_graph_4_ge,\n",
    "    num_time_steps,\n",
    "    step_size,\n",
    "    node_noise_level=0.04,\n",
    "    edge_noise_level=5.0,\n",
    "    global_noise_level=1.0)\n",
    "_, true_nodes_rollout_4_ge = roll_out_physics(\n",
    "    simulator, initial_conditions_4_ge, num_time_steps, step_size)\n",
    "_, predicted_nodes_rollout_4_ge = roll_out_physics(\n",
    "    lambda x: model(x, num_processing_steps_ge), initial_conditions_4_ge,\n",
    "    num_time_steps, step_size)\n",
    "# Test data: 9-mass string.\n",
    "initial_conditions_9_ge, true_trajectory_9_ge = generate_trajectory(\n",
    "    lambda x: model(x, num_processing_steps_ge),\n",
    "    base_graph_9_ge,\n",
    "    num_time_steps,\n",
    "    step_size,\n",
    "    node_noise_level=0.04,\n",
    "    edge_noise_level=5.0,\n",
    "    global_noise_level=1.0)\n",
    "_, true_nodes_rollout_9_ge = roll_out_physics(\n",
    "    simulator, initial_conditions_9_ge, num_time_steps, step_size)\n",
    "_, predicted_nodes_rollout_9_ge = roll_out_physics(\n",
    "    lambda x: model(x, num_processing_steps_ge), initial_conditions_9_ge,\n",
    "    num_time_steps, step_size)\n",
    "\n",
    "# Training loss.\n",
    "loss_ops_tr = create_loss_ops(target_nodes_tr, output_ops_tr)\n",
    "# Training loss across processing steps.\n",
    "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
    "# Test/generalization loss: 4-mass.\n",
    "loss_op_4_ge = tf.reduce_mean(\n",
    "    tf.reduce_sum(\n",
    "        (predicted_nodes_rollout_4_ge[..., 2:4] -\n",
    "         true_nodes_rollout_4_ge[..., 2:4])**2,\n",
    "        axis=-1))\n",
    "# Test/generalization loss: 9-mass string.\n",
    "loss_op_9_ge = tf.reduce_mean(\n",
    "    tf.reduce_sum(\n",
    "        (predicted_nodes_rollout_9_ge[..., 2:4] -\n",
    "         true_nodes_rollout_9_ge[..., 2:4])**2,\n",
    "        axis=-1))\n",
    "\n",
    "# Optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "step_op = optimizer.minimize(loss_op_tr)\n",
    "\n",
    "input_graph_tr = make_all_runnable_in_session(input_graph_tr)\n",
    "initial_conditions_4_ge = make_all_runnable_in_session(initial_conditions_4_ge)\n",
    "initial_conditions_9_ge = make_all_runnable_in_session(initial_conditions_9_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "TpABTYk0Ap-V"
   },
   "outputs": [],
   "source": [
    "#@title Reset session  { form-width: \"30%\" }\n",
    "\n",
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "\n",
    "try:\n",
    "  sess.close()\n",
    "except NameError:\n",
    "  pass\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 0\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "losses_4_ge = []\n",
    "losses_9_ge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4PCPvXiHA7q7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# (iteration number), T (elapsed seconds), Ltr (training 1-step loss), Lge4 (test/generalization rollout loss for 4-mass strings), Lge9 (test/generalization rollout loss for 9-mass strings)\n",
      "# 00043, T 22.3, Ltr 3.9196, Lge4 3.0919, Lge9 11.7603\n",
      "# 00088, T 40.9, Ltr 3.2136, Lge4 4.1908, Lge9 10.4635\n",
      "# 00137, T 61.1, Ltr 2.4901, Lge4 5.0422, Lge9 7.5275\n",
      "# 00186, T 81.6, Ltr 2.5647, Lge4 4.8297, Lge9 6.2907\n",
      "# 00234, T 101.7, Ltr 1.0130, Lge4 5.1298, Lge9 7.4277\n",
      "# 00282, T 121.8, Ltr 2.0394, Lge4 3.3996, Lge9 17.4669\n",
      "# 00330, T 142.1, Ltr 1.9814, Lge4 4.6338, Lge9 13.6588\n",
      "# 00379, T 162.5, Ltr 1.8639, Lge4 3.9924, Lge9 13.2861\n",
      "# 00427, T 182.8, Ltr 1.9835, Lge4 2.9213, Lge9 20.0842\n",
      "# 00474, T 203.1, Ltr 1.4043, Lge4 3.2902, Lge9 18.0523\n",
      "# 00522, T 223.4, Ltr 1.1342, Lge4 5.7235, Lge9 13.2660\n",
      "# 00570, T 243.5, Ltr 1.5420, Lge4 3.0632, Lge9 20.2138\n",
      "# 00619, T 263.7, Ltr 1.6949, Lge4 2.0637, Lge9 8.6774\n",
      "# 00665, T 283.9, Ltr 2.1556, Lge4 2.1312, Lge9 12.7714\n",
      "# 00711, T 304.1, Ltr 1.6069, Lge4 2.7022, Lge9 18.0707\n",
      "# 00755, T 324.3, Ltr 0.8550, Lge4 2.9669, Lge9 5.2515\n",
      "# 00803, T 344.6, Ltr 0.8114, Lge4 2.6963, Lge9 16.6376\n",
      "# 00851, T 364.7, Ltr 1.3291, Lge4 1.6857, Lge9 21.2299\n",
      "# 00900, T 384.8, Ltr 1.3778, Lge4 2.5667, Lge9 18.9692\n",
      "# 00949, T 405.0, Ltr 1.3053, Lge4 2.5374, Lge9 11.3696\n",
      "# 00998, T 425.1, Ltr 1.1128, Lge4 6.2479, Lge9 8.6357\n",
      "# 01047, T 445.4, Ltr 0.6735, Lge4 2.4686, Lge9 13.9511\n",
      "# 01096, T 465.6, Ltr 1.1917, Lge4 3.6957, Lge9 20.7757\n",
      "# 01144, T 485.8, Ltr 0.6847, Lge4 2.1224, Lge9 8.3520\n",
      "# 01193, T 506.0, Ltr 0.7903, Lge4 1.7664, Lge9 8.5568\n",
      "# 01242, T 526.2, Ltr 0.9098, Lge4 3.3912, Lge9 11.6395\n",
      "# 01291, T 546.4, Ltr 0.6728, Lge4 1.9474, Lge9 9.4452\n",
      "# 01340, T 566.7, Ltr 1.2010, Lge4 1.8323, Lge9 11.7680\n",
      "# 01389, T 586.9, Ltr 1.1121, Lge4 2.1994, Lge9 5.9022\n",
      "# 01438, T 607.1, Ltr 0.7082, Lge4 8.2617, Lge9 9.8893\n",
      "# 01487, T 627.3, Ltr 0.0528, Lge4 1.5405, Lge9 15.6143\n",
      "# 01536, T 647.5, Ltr 0.4437, Lge4 1.7891, Lge9 8.9715\n",
      "# 01585, T 667.7, Ltr 1.2150, Lge4 2.0339, Lge9 8.6539\n",
      "# 01633, T 687.9, Ltr 0.5931, Lge4 8.5313, Lge9 12.5952\n",
      "# 01682, T 708.0, Ltr 1.2994, Lge4 5.7197, Lge9 13.5105\n",
      "# 01731, T 728.2, Ltr 0.5578, Lge4 2.0334, Lge9 12.3533\n",
      "# 01780, T 748.4, Ltr 1.1160, Lge4 1.4444, Lge9 8.2723\n",
      "# 01829, T 769.0, Ltr 1.0868, Lge4 1.9398, Lge9 12.2808\n",
      "# 01876, T 789.0, Ltr 0.5508, Lge4 1.7976, Lge9 15.5403\n",
      "# 01925, T 809.3, Ltr 1.0999, Lge4 2.6720, Lge9 9.4268\n",
      "# 01974, T 829.5, Ltr 0.6010, Lge4 1.7071, Lge9 10.1510\n",
      "# 02023, T 849.6, Ltr 1.1810, Lge4 2.1111, Lge9 8.8424\n",
      "# 02072, T 870.0, Ltr 1.1717, Lge4 2.0190, Lge9 13.6141\n",
      "# 02120, T 890.0, Ltr 1.1878, Lge4 6.0032, Lge9 6.2806\n",
      "# 02169, T 910.3, Ltr 0.5594, Lge4 6.6639, Lge9 12.3440\n",
      "# 02218, T 930.7, Ltr 0.2057, Lge4 1.7895, Lge9 8.3732\n",
      "# 02266, T 950.7, Ltr 0.9149, Lge4 1.7935, Lge9 9.2271\n",
      "# 02314, T 970.9, Ltr 0.8301, Lge4 1.5343, Lge9 5.7581\n",
      "# 02363, T 991.3, Ltr 0.9570, Lge4 2.4090, Lge9 7.3260\n",
      "# 02412, T 1011.6, Ltr 0.2318, Lge4 1.7226, Lge9 11.2204\n",
      "# 02461, T 1032.0, Ltr 0.8458, Lge4 2.5112, Lge9 9.2737\n",
      "# 02510, T 1052.3, Ltr 0.8814, Lge4 2.1156, Lge9 17.8167\n",
      "# 02559, T 1072.5, Ltr 0.9232, Lge4 1.8340, Lge9 7.3592\n",
      "# 02608, T 1092.7, Ltr 0.8879, Lge4 3.1831, Lge9 12.0514\n",
      "# 02657, T 1112.9, Ltr 1.0121, Lge4 1.9629, Lge9 7.9977\n",
      "# 02705, T 1132.9, Ltr 0.7623, Lge4 4.6029, Lge9 6.7203\n",
      "# 02754, T 1153.1, Ltr 0.9819, Lge4 2.5667, Lge9 13.1942\n",
      "# 02803, T 1173.5, Ltr 0.8518, Lge4 1.8555, Lge9 6.9489\n",
      "# 02852, T 1193.7, Ltr 0.5601, Lge4 7.6449, Lge9 11.4065\n",
      "# 02901, T 1213.8, Ltr 0.6025, Lge4 3.5101, Lge9 9.0072\n",
      "# 02950, T 1234.1, Ltr 1.1298, Lge4 3.0049, Lge9 6.7711\n",
      "# 02999, T 1254.3, Ltr 0.5721, Lge4 3.8829, Lge9 7.0688\n",
      "# 03048, T 1274.4, Ltr 0.7563, Lge4 2.0268, Lge9 7.0694\n",
      "# 03097, T 1294.8, Ltr 0.8876, Lge4 1.8839, Lge9 6.4834\n",
      "# 03146, T 1315.0, Ltr 0.4158, Lge4 2.1252, Lge9 9.0769\n",
      "# 03195, T 1335.2, Ltr 0.5192, Lge4 4.7514, Lge9 13.0836\n",
      "# 03244, T 1355.4, Ltr 0.6338, Lge4 1.6053, Lge9 6.1800\n",
      "# 03293, T 1375.6, Ltr 0.1407, Lge4 2.0026, Lge9 11.6585\n",
      "# 03341, T 1395.6, Ltr 0.6847, Lge4 1.8081, Lge9 8.6719\n",
      "# 03390, T 1416.0, Ltr 0.5885, Lge4 6.4217, Lge9 10.6394\n",
      "# 03438, T 1436.2, Ltr 0.9532, Lge4 1.9631, Lge9 10.0700\n",
      "# 03487, T 1456.4, Ltr 0.6490, Lge4 1.8957, Lge9 5.9224\n",
      "# 03534, T 1476.6, Ltr 0.3499, Lge4 1.8179, Lge9 6.9853\n",
      "# 03578, T 1497.0, Ltr 0.2632, Lge4 1.8391, Lge9 7.8789\n",
      "# 03626, T 1517.2, Ltr 0.2705, Lge4 1.2417, Lge9 6.8060\n",
      "# 03674, T 1537.2, Ltr 0.4969, Lge4 1.7044, Lge9 5.7066\n",
      "# 03723, T 1557.3, Ltr 0.9760, Lge4 2.3677, Lge9 10.6339\n",
      "# 03772, T 1577.6, Ltr 0.2268, Lge4 2.2384, Lge9 8.2875\n",
      "# 03821, T 1597.8, Ltr 0.4290, Lge4 2.1214, Lge9 7.7688\n",
      "# 03870, T 1617.9, Ltr 0.6268, Lge4 1.8310, Lge9 5.8790\n",
      "# 03919, T 1638.1, Ltr 0.6408, Lge4 1.8968, Lge9 9.8590\n",
      "# 03968, T 1658.4, Ltr 0.3040, Lge4 1.8564, Lge9 12.5759\n",
      "# 04017, T 1678.6, Ltr 0.7414, Lge4 1.9103, Lge9 5.4068\n",
      "# 04066, T 1698.8, Ltr 0.4641, Lge4 2.4399, Lge9 5.6626\n",
      "# 04115, T 1719.0, Ltr 0.6332, Lge4 1.9441, Lge9 6.5673\n",
      "# 04163, T 1739.2, Ltr 0.5583, Lge4 1.7268, Lge9 12.8470\n",
      "# 04212, T 1759.4, Ltr 0.2309, Lge4 1.4746, Lge9 4.9916\n",
      "# 04261, T 1779.7, Ltr 0.5217, Lge4 1.5528, Lge9 6.9287\n",
      "# 04310, T 1799.9, Ltr 0.6795, Lge4 1.6321, Lge9 4.4845\n",
      "# 04359, T 1820.1, Ltr 0.6259, Lge4 1.6506, Lge9 6.9194\n",
      "# 04408, T 1840.2, Ltr 0.5821, Lge4 2.3711, Lge9 10.4487\n",
      "# 04457, T 1860.5, Ltr 0.2888, Lge4 2.1962, Lge9 6.2137\n",
      "# 04506, T 1880.7, Ltr 0.5792, Lge4 1.7669, Lge9 9.8304\n",
      "# 04555, T 1901.0, Ltr 0.0751, Lge4 1.8281, Lge9 3.6713\n",
      "# 04604, T 1921.2, Ltr 0.6513, Lge4 1.4731, Lge9 6.9666\n",
      "# 04653, T 1941.6, Ltr 0.3937, Lge4 1.5351, Lge9 8.5839\n",
      "# 04702, T 1961.8, Ltr 0.6686, Lge4 1.2313, Lge9 9.4876\n",
      "# 04751, T 1982.0, Ltr 0.4764, Lge4 0.9475, Lge9 5.3664\n",
      "# 04800, T 2002.3, Ltr 0.6677, Lge4 1.0847, Lge9 8.2531\n",
      "# 04849, T 2022.5, Ltr 0.3764, Lge4 2.1712, Lge9 10.0951\n",
      "# 04898, T 2042.7, Ltr 0.0748, Lge4 1.7051, Lge9 13.3907\n",
      "# 04947, T 2062.9, Ltr 0.0846, Lge4 1.2365, Lge9 7.9934\n",
      "# 04996, T 2083.1, Ltr 0.2730, Lge4 0.8343, Lge9 5.9868\n",
      "# 05045, T 2103.3, Ltr 0.0570, Lge4 1.6305, Lge9 4.9079\n",
      "# 05093, T 2123.5, Ltr 0.6956, Lge4 1.5604, Lge9 5.2141\n",
      "# 05142, T 2143.7, Ltr 0.4833, Lge4 1.2201, Lge9 5.5638\n",
      "# 05191, T 2164.0, Ltr 0.0531, Lge4 1.2540, Lge9 5.2561\n",
      "# 05237, T 2183.9, Ltr 0.3002, Lge4 1.5317, Lge9 7.1477\n",
      "# 05285, T 2204.0, Ltr 0.5440, Lge4 1.6011, Lge9 4.7037\n",
      "# 05333, T 2224.0, Ltr 0.2263, Lge4 1.8341, Lge9 8.1375\n",
      "# 05382, T 2244.4, Ltr 0.6585, Lge4 1.3593, Lge9 7.4693\n",
      "# 05431, T 2264.6, Ltr 0.6091, Lge4 0.9119, Lge9 20.4023\n",
      "# 05480, T 2284.7, Ltr 0.2479, Lge4 1.4802, Lge9 5.8512\n",
      "# 05529, T 2304.9, Ltr 0.5226, Lge4 0.9180, Lge9 6.1283\n",
      "# 05578, T 2325.1, Ltr 0.6828, Lge4 1.4795, Lge9 8.1498\n",
      "# 05627, T 2345.3, Ltr 0.5639, Lge4 1.8500, Lge9 9.1563\n",
      "# 05675, T 2365.4, Ltr 0.5152, Lge4 2.0004, Lge9 4.9128\n",
      "# 05724, T 2385.5, Ltr 0.5867, Lge4 1.2290, Lge9 4.0337\n",
      "# 05773, T 2405.7, Ltr 0.4626, Lge4 0.9858, Lge9 4.7951\n",
      "# 05822, T 2425.9, Ltr 0.2468, Lge4 1.6306, Lge9 2.7945\n",
      "# 05871, T 2446.0, Ltr 0.5810, Lge4 1.0602, Lge9 6.7182\n",
      "# 05920, T 2466.2, Ltr 0.5946, Lge4 0.8637, Lge9 14.3142\n",
      "# 05969, T 2486.7, Ltr 0.4002, Lge4 1.1810, Lge9 10.4089\n",
      "# 06018, T 2506.8, Ltr 0.5706, Lge4 1.9431, Lge9 11.0201\n",
      "# 06067, T 2527.0, Ltr 0.2653, Lge4 1.0505, Lge9 3.2450\n",
      "# 06115, T 2547.2, Ltr 0.5020, Lge4 1.2415, Lge9 5.2888\n",
      "# 06164, T 2567.3, Ltr 0.4129, Lge4 1.1751, Lge9 4.5987\n",
      "# 06213, T 2587.5, Ltr 0.5745, Lge4 2.1044, Lge9 14.4359\n",
      "# 06261, T 2607.7, Ltr 0.5976, Lge4 1.0752, Lge9 7.1585\n",
      "# 06310, T 2627.9, Ltr 0.6132, Lge4 3.9090, Lge9 7.4558\n",
      "# 06358, T 2648.3, Ltr 0.9646, Lge4 1.9908, Lge9 14.2080\n",
      "# 06406, T 2668.4, Ltr 0.5528, Lge4 1.4307, Lge9 6.9919\n",
      "# 06455, T 2688.7, Ltr 0.5084, Lge4 1.3094, Lge9 4.1158\n",
      "# 06504, T 2709.0, Ltr 0.3797, Lge4 1.6401, Lge9 4.7152\n",
      "# 06552, T 2729.1, Ltr 0.5298, Lge4 1.2731, Lge9 3.9564\n",
      "# 06601, T 2749.4, Ltr 0.3271, Lge4 1.1135, Lge9 8.0685\n",
      "# 06650, T 2769.7, Ltr 0.5197, Lge4 1.2670, Lge9 8.1856\n",
      "# 06699, T 2789.9, Ltr 0.4491, Lge4 1.0159, Lge9 5.3561\n",
      "# 06748, T 2810.1, Ltr 0.5256, Lge4 1.3593, Lge9 12.0464\n",
      "# 06797, T 2830.4, Ltr 0.3356, Lge4 1.0733, Lge9 5.8663\n",
      "# 06845, T 2850.4, Ltr 0.5628, Lge4 1.0836, Lge9 11.1517\n",
      "# 06894, T 2870.6, Ltr 0.8620, Lge4 1.9076, Lge9 10.1061\n",
      "# 06943, T 2890.9, Ltr 0.6175, Lge4 1.6398, Lge9 6.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 06992, T 2911.1, Ltr 0.3877, Lge4 0.9054, Lge9 3.9724\n",
      "# 07041, T 2931.4, Ltr 0.4863, Lge4 0.8681, Lge9 10.0523\n",
      "# 07090, T 2951.6, Ltr 0.4881, Lge4 1.1507, Lge9 7.2593\n",
      "# 07138, T 2971.7, Ltr 0.3654, Lge4 0.8697, Lge9 6.8722\n",
      "# 07187, T 2991.9, Ltr 0.4650, Lge4 1.0995, Lge9 5.8505\n",
      "# 07236, T 3012.2, Ltr 0.4699, Lge4 1.5656, Lge9 4.9092\n",
      "# 07285, T 3032.4, Ltr 0.3736, Lge4 1.8393, Lge9 3.2600\n",
      "# 07334, T 3052.6, Ltr 0.2309, Lge4 1.5106, Lge9 8.4339\n",
      "# 07383, T 3072.9, Ltr 0.4166, Lge4 1.1931, Lge9 4.7526\n",
      "# 07431, T 3093.0, Ltr 0.3919, Lge4 0.8580, Lge9 4.2742\n",
      "# 07480, T 3113.3, Ltr 0.3594, Lge4 1.5094, Lge9 6.5095\n",
      "# 07528, T 3133.5, Ltr 0.5257, Lge4 1.5636, Lge9 5.9119\n",
      "# 07577, T 3153.8, Ltr 0.0791, Lge4 1.3894, Lge9 9.3582\n",
      "# 07626, T 3174.0, Ltr 0.3452, Lge4 2.6350, Lge9 5.0484\n",
      "# 07675, T 3194.2, Ltr 0.3000, Lge4 1.3316, Lge9 9.3536\n",
      "# 07723, T 3214.4, Ltr 0.1190, Lge4 1.7914, Lge9 8.0463\n",
      "# 07772, T 3234.6, Ltr 0.4595, Lge4 1.4639, Lge9 13.2348\n",
      "# 07821, T 3254.9, Ltr 0.3874, Lge4 1.1679, Lge9 4.2658\n",
      "# 07870, T 3275.1, Ltr 0.2507, Lge4 1.2364, Lge9 7.7043\n",
      "# 07919, T 3295.3, Ltr 0.5026, Lge4 1.6064, Lge9 7.9318\n",
      "# 07968, T 3315.5, Ltr 0.0506, Lge4 1.4718, Lge9 5.2601\n",
      "# 08016, T 3335.7, Ltr 0.4334, Lge4 1.7489, Lge9 5.1809\n",
      "# 08065, T 3355.9, Ltr 0.4719, Lge4 1.4494, Lge9 4.3967\n",
      "# 08114, T 3376.1, Ltr 0.5972, Lge4 11.3058, Lge9 5.8786\n",
      "# 08163, T 3396.3, Ltr 0.2214, Lge4 1.2857, Lge9 5.7413\n",
      "# 08212, T 3416.5, Ltr 0.0378, Lge4 1.1205, Lge9 20.2609\n",
      "# 08261, T 3436.8, Ltr 0.4553, Lge4 2.1149, Lge9 4.5007\n",
      "# 08309, T 3457.0, Ltr 0.0390, Lge4 1.3980, Lge9 3.8789\n",
      "# 08358, T 3477.2, Ltr 0.0374, Lge4 1.5096, Lge9 5.4214\n",
      "# 08407, T 3497.5, Ltr 0.4618, Lge4 1.1430, Lge9 3.9921\n",
      "# 08456, T 3517.7, Ltr 0.4172, Lge4 1.0977, Lge9 9.7443\n",
      "# 08505, T 3537.9, Ltr 0.4363, Lge4 1.0733, Lge9 2.9248\n",
      "# 08554, T 3558.2, Ltr 0.3656, Lge4 1.4301, Lge9 3.8628\n",
      "# 08602, T 3578.4, Ltr 0.3660, Lge4 1.2911, Lge9 3.7409\n",
      "# 08651, T 3598.6, Ltr 0.0706, Lge4 1.1385, Lge9 7.9067\n",
      "# 08700, T 3618.8, Ltr 0.4888, Lge4 1.5218, Lge9 6.4985\n",
      "# 08749, T 3639.1, Ltr 0.4130, Lge4 1.3098, Lge9 6.7699\n",
      "# 08798, T 3659.3, Ltr 0.4643, Lge4 1.5069, Lge9 4.7577\n",
      "# 08847, T 3679.6, Ltr 0.4769, Lge4 1.4701, Lge9 3.3172\n",
      "# 08895, T 3699.8, Ltr 0.1676, Lge4 1.3167, Lge9 4.1872\n",
      "# 08944, T 3720.0, Ltr 0.4635, Lge4 1.4731, Lge9 3.7605\n",
      "# 08993, T 3740.2, Ltr 0.4920, Lge4 2.2778, Lge9 7.2787\n",
      "# 09042, T 3760.5, Ltr 0.2109, Lge4 1.6474, Lge9 3.5661\n",
      "# 09089, T 3780.5, Ltr 0.1461, Lge4 1.7538, Lge9 3.4484\n",
      "# 09138, T 3800.9, Ltr 0.2669, Lge4 1.5001, Lge9 3.4497\n",
      "# 09187, T 3821.3, Ltr 0.1046, Lge4 1.3606, Lge9 6.4939\n",
      "# 09236, T 3841.5, Ltr 0.4280, Lge4 1.4553, Lge9 6.0842\n",
      "# 09285, T 3861.7, Ltr 0.0470, Lge4 1.5842, Lge9 2.8279\n",
      "# 09334, T 3882.0, Ltr 0.2781, Lge4 1.5550, Lge9 5.3527\n",
      "# 09383, T 3902.2, Ltr 0.2352, Lge4 1.6238, Lge9 5.4114\n",
      "# 09432, T 3922.6, Ltr 0.2739, Lge4 1.5244, Lge9 2.5965\n",
      "# 09480, T 3942.7, Ltr 0.3045, Lge4 1.7616, Lge9 4.0355\n",
      "# 09529, T 3963.0, Ltr 0.4678, Lge4 2.3024, Lge9 6.3602\n",
      "# 09578, T 3983.2, Ltr 0.1880, Lge4 1.4982, Lge9 7.0692\n",
      "# 09627, T 4003.4, Ltr 0.4236, Lge4 1.4043, Lge9 5.7548\n",
      "# 09676, T 4023.6, Ltr 0.4051, Lge4 1.8082, Lge9 4.7403\n",
      "# 09724, T 4043.8, Ltr 0.4788, Lge4 2.1492, Lge9 6.4132\n",
      "# 09773, T 4064.0, Ltr 0.2579, Lge4 2.5241, Lge9 9.0658\n",
      "# 09822, T 4084.3, Ltr 0.4291, Lge4 2.0471, Lge9 6.2577\n",
      "# 09871, T 4104.5, Ltr 0.3177, Lge4 1.5802, Lge9 6.8826\n",
      "# 09920, T 4124.7, Ltr 0.3555, Lge4 1.6827, Lge9 6.2828\n",
      "# 09969, T 4145.0, Ltr 0.3600, Lge4 1.6084, Lge9 5.6282\n",
      "# 10017, T 4165.1, Ltr 0.3664, Lge4 1.7204, Lge9 4.2720\n",
      "# 10066, T 4185.3, Ltr 0.2958, Lge4 1.1827, Lge9 6.0817\n",
      "# 10115, T 4205.6, Ltr 0.4633, Lge4 0.9830, Lge9 8.0599\n",
      "# 10164, T 4225.8, Ltr 0.0988, Lge4 1.5075, Lge9 6.8374\n",
      "# 10213, T 4246.0, Ltr 0.3080, Lge4 1.4834, Lge9 3.6592\n",
      "# 10262, T 4266.2, Ltr 0.1268, Lge4 1.7509, Lge9 4.6128\n",
      "# 10310, T 4286.3, Ltr 0.0573, Lge4 1.5709, Lge9 3.1973\n",
      "# 10359, T 4306.6, Ltr 0.3230, Lge4 1.9098, Lge9 3.2092\n",
      "# 10408, T 4326.8, Ltr 0.2349, Lge4 1.2722, Lge9 6.7587\n",
      "# 10457, T 4347.0, Ltr 0.4818, Lge4 1.2900, Lge9 13.7060\n",
      "# 10506, T 4367.3, Ltr 0.3949, Lge4 1.7029, Lge9 4.3062\n",
      "# 10555, T 4387.6, Ltr 0.0832, Lge4 2.7082, Lge9 4.0088\n",
      "# 10603, T 4407.7, Ltr 0.2674, Lge4 2.0313, Lge9 5.3130\n",
      "# 10651, T 4427.7, Ltr 0.3901, Lge4 3.6236, Lge9 5.1208\n",
      "# 10700, T 4448.0, Ltr 0.2974, Lge4 1.8432, Lge9 3.7070\n",
      "# 10749, T 4468.2, Ltr 0.0892, Lge4 1.7825, Lge9 5.8394\n",
      "# 10798, T 4488.5, Ltr 0.3564, Lge4 1.9656, Lge9 10.5360\n",
      "# 10847, T 4508.7, Ltr 0.2834, Lge4 1.4071, Lge9 3.8245\n",
      "# 10895, T 4528.9, Ltr 0.2570, Lge4 2.0682, Lge9 7.3434\n",
      "# 10944, T 4549.2, Ltr 0.3999, Lge4 1.1176, Lge9 4.0953\n",
      "# 10993, T 4569.4, Ltr 0.2261, Lge4 1.0347, Lge9 4.9685\n",
      "# 11042, T 4589.7, Ltr 0.3386, Lge4 2.4221, Lge9 7.9735\n",
      "# 11091, T 4610.0, Ltr 0.2797, Lge4 1.4159, Lge9 4.2786\n",
      "# 11140, T 4630.2, Ltr 0.2954, Lge4 3.0127, Lge9 6.8845\n",
      "# 11188, T 4650.3, Ltr 0.3093, Lge4 0.8106, Lge9 5.2303\n",
      "# 11236, T 4670.4, Ltr 0.2123, Lge4 1.4330, Lge9 4.0472\n",
      "# 11285, T 4690.7, Ltr 0.1715, Lge4 0.7893, Lge9 5.4408\n",
      "# 11334, T 4710.9, Ltr 0.3836, Lge4 1.0634, Lge9 5.2272\n",
      "# 11383, T 4731.3, Ltr 0.0451, Lge4 1.0400, Lge9 3.7074\n",
      "# 11432, T 4751.5, Ltr 0.3324, Lge4 1.4164, Lge9 5.1086\n",
      "# 11480, T 4771.6, Ltr 0.1103, Lge4 2.5902, Lge9 4.1183\n",
      "# 11529, T 4791.9, Ltr 0.2726, Lge4 1.1360, Lge9 4.2263\n",
      "# 11578, T 4812.2, Ltr 0.0410, Lge4 1.1719, Lge9 3.9005\n",
      "# 11627, T 4832.4, Ltr 0.3362, Lge4 1.3658, Lge9 3.8888\n",
      "# 11676, T 4852.7, Ltr 0.2624, Lge4 0.6493, Lge9 8.1608\n",
      "# 11725, T 4872.9, Ltr 0.2513, Lge4 1.5312, Lge9 4.7059\n",
      "# 11773, T 4893.0, Ltr 0.1330, Lge4 1.8318, Lge9 4.7647\n",
      "# 11822, T 4913.3, Ltr 0.3381, Lge4 0.7804, Lge9 5.9699\n",
      "# 11871, T 4933.5, Ltr 0.1899, Lge4 1.4265, Lge9 7.6608\n",
      "# 11919, T 4953.8, Ltr 0.1076, Lge4 1.5633, Lge9 6.0970\n",
      "# 11968, T 4974.1, Ltr 0.0713, Lge4 2.2253, Lge9 5.0393\n",
      "# 12017, T 4994.3, Ltr 0.2205, Lge4 1.3633, Lge9 3.7988\n",
      "# 12065, T 5014.5, Ltr 0.2135, Lge4 1.6087, Lge9 4.2180\n",
      "# 12114, T 5034.8, Ltr 0.2091, Lge4 0.8891, Lge9 6.7761\n",
      "# 12163, T 5055.0, Ltr 0.0528, Lge4 1.0351, Lge9 11.2999\n",
      "# 12212, T 5075.3, Ltr 0.2261, Lge4 0.7624, Lge9 9.2353\n",
      "# 12261, T 5095.7, Ltr 0.1214, Lge4 2.0100, Lge9 8.3051\n",
      "# 12310, T 5116.0, Ltr 0.3560, Lge4 0.8197, Lge9 2.7217\n",
      "# 12358, T 5136.3, Ltr 0.2940, Lge4 0.9285, Lge9 3.7046\n",
      "# 12406, T 5156.4, Ltr 0.2496, Lge4 2.1022, Lge9 9.5186\n",
      "# 12455, T 5176.7, Ltr 0.2628, Lge4 1.0662, Lge9 4.0088\n",
      "# 12504, T 5196.9, Ltr 0.3209, Lge4 2.2078, Lge9 10.0678\n",
      "# 12553, T 5217.2, Ltr 0.1316, Lge4 2.9727, Lge9 2.8507\n",
      "# 12602, T 5237.5, Ltr 0.2766, Lge4 0.7162, Lge9 3.4089\n",
      "# 12650, T 5257.7, Ltr 0.3490, Lge4 1.0072, Lge9 4.2265\n",
      "# 12699, T 5278.0, Ltr 0.1876, Lge4 0.5501, Lge9 3.2796\n",
      "# 12748, T 5298.2, Ltr 0.2212, Lge4 2.4108, Lge9 4.9252\n",
      "# 12797, T 5318.5, Ltr 0.2218, Lge4 3.8184, Lge9 5.6977\n",
      "# 12846, T 5338.8, Ltr 0.2038, Lge4 2.4447, Lge9 4.4549\n",
      "# 12895, T 5359.1, Ltr 0.1929, Lge4 0.7764, Lge9 5.4261\n",
      "# 12943, T 5379.3, Ltr 0.0945, Lge4 0.9391, Lge9 3.4104\n",
      "# 12992, T 5399.5, Ltr 0.1931, Lge4 0.7276, Lge9 3.8621\n",
      "# 13041, T 5419.8, Ltr 0.1048, Lge4 0.8343, Lge9 3.2185\n",
      "# 13090, T 5440.1, Ltr 0.0402, Lge4 1.2244, Lge9 6.2812\n",
      "# 13139, T 5460.3, Ltr 0.1803, Lge4 1.4383, Lge9 5.9979\n",
      "# 13188, T 5480.6, Ltr 0.2519, Lge4 1.4986, Lge9 3.3569\n",
      "# 13236, T 5500.8, Ltr 0.1127, Lge4 0.9521, Lge9 3.3938\n",
      "# 13285, T 5521.1, Ltr 0.3049, Lge4 0.7311, Lge9 5.6856\n",
      "# 13333, T 5541.2, Ltr 0.2151, Lge4 1.6206, Lge9 6.3068\n",
      "# 13381, T 5561.4, Ltr 0.2464, Lge4 0.7394, Lge9 3.6460\n",
      "# 13430, T 5581.6, Ltr 0.2349, Lge4 0.5886, Lge9 5.6321\n",
      "# 13479, T 5602.0, Ltr 0.4283, Lge4 0.5747, Lge9 7.0504\n",
      "# 13528, T 5622.3, Ltr 0.2700, Lge4 1.1351, Lge9 4.1496\n",
      "# 13577, T 5642.6, Ltr 0.2175, Lge4 1.3309, Lge9 3.3987\n",
      "# 13626, T 5662.8, Ltr 0.1663, Lge4 1.7224, Lge9 3.6493\n",
      "# 13675, T 5683.1, Ltr 0.0847, Lge4 5.2252, Lge9 5.0469\n",
      "# 13724, T 5703.3, Ltr 0.1265, Lge4 0.6010, Lge9 3.4226\n",
      "# 13772, T 5723.3, Ltr 0.1233, Lge4 0.5330, Lge9 3.0747\n",
      "# 13820, T 5743.5, Ltr 0.2243, Lge4 0.7052, Lge9 3.9298\n",
      "# 13868, T 5763.6, Ltr 0.1155, Lge4 1.1465, Lge9 5.5432\n",
      "# 13917, T 5783.9, Ltr 0.0385, Lge4 2.6766, Lge9 3.7909\n",
      "# 13966, T 5804.2, Ltr 0.0826, Lge4 0.7317, Lge9 2.9513\n",
      "# 14015, T 5824.4, Ltr 0.1698, Lge4 1.1570, Lge9 5.1785\n",
      "# 14063, T 5844.6, Ltr 0.2140, Lge4 2.4739, Lge9 12.6795\n",
      "# 14112, T 5864.9, Ltr 0.1973, Lge4 1.3968, Lge9 4.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 14161, T 5885.2, Ltr 0.2076, Lge4 0.9451, Lge9 6.2229\n",
      "# 14210, T 5905.4, Ltr 0.2334, Lge4 2.2305, Lge9 5.6971\n",
      "# 14259, T 5925.7, Ltr 0.2847, Lge4 0.9447, Lge9 6.3344\n",
      "# 14308, T 5946.0, Ltr 0.2741, Lge4 0.6598, Lge9 5.6166\n",
      "# 14356, T 5966.1, Ltr 0.2067, Lge4 2.1853, Lge9 8.6999\n",
      "# 14405, T 5986.4, Ltr 0.0798, Lge4 1.2870, Lge9 6.2646\n",
      "# 14453, T 6006.4, Ltr 0.1675, Lge4 4.7256, Lge9 8.7304\n",
      "# 14502, T 6026.7, Ltr 0.1858, Lge4 1.9772, Lge9 3.4229\n",
      "# 14551, T 6046.9, Ltr 0.0610, Lge4 1.4306, Lge9 5.1209\n",
      "# 14600, T 6067.2, Ltr 0.1694, Lge4 0.8608, Lge9 5.4226\n",
      "# 14648, T 6087.3, Ltr 0.0272, Lge4 1.4102, Lge9 4.0789\n",
      "# 14697, T 6107.5, Ltr 0.1470, Lge4 2.1977, Lge9 5.8193\n",
      "# 14746, T 6127.8, Ltr 0.0977, Lge4 1.2589, Lge9 4.8160\n",
      "# 14795, T 6148.1, Ltr 0.1845, Lge4 1.3206, Lge9 3.2246\n",
      "# 14844, T 6168.3, Ltr 0.1715, Lge4 0.6641, Lge9 3.8348\n",
      "# 14893, T 6188.6, Ltr 0.1446, Lge4 1.5590, Lge9 3.5656\n",
      "# 14941, T 6208.7, Ltr 0.1683, Lge4 0.9224, Lge9 2.8627\n",
      "# 14990, T 6229.0, Ltr 0.2191, Lge4 2.8836, Lge9 6.0579\n",
      "# 15039, T 6249.3, Ltr 0.7869, Lge4 1.7710, Lge9 4.7225\n",
      "# 15088, T 6269.6, Ltr 0.1810, Lge4 4.4252, Lge9 4.4571\n",
      "# 15136, T 6289.6, Ltr 0.1440, Lge4 0.7588, Lge9 3.3399\n",
      "# 15184, T 6309.8, Ltr 0.2061, Lge4 0.6479, Lge9 3.7525\n",
      "# 15230, T 6329.9, Ltr 0.2819, Lge4 1.4081, Lge9 9.8734\n",
      "# 15279, T 6350.2, Ltr 0.2657, Lge4 1.8517, Lge9 4.7458\n",
      "# 15327, T 6370.4, Ltr 0.1155, Lge4 0.6260, Lge9 7.4892\n",
      "# 15376, T 6390.6, Ltr 0.0989, Lge4 0.6635, Lge9 4.0595\n",
      "# 15425, T 6410.9, Ltr 0.0768, Lge4 1.1500, Lge9 3.2618\n",
      "# 15473, T 6431.0, Ltr 0.0878, Lge4 1.0275, Lge9 3.4867\n",
      "# 15521, T 6451.2, Ltr 0.0881, Lge4 0.8604, Lge9 4.1764\n",
      "# 15570, T 6471.5, Ltr 0.0365, Lge4 0.7111, Lge9 5.0328\n",
      "# 15619, T 6491.8, Ltr 0.1988, Lge4 3.6516, Lge9 4.4536\n",
      "# 15668, T 6512.0, Ltr 0.2571, Lge4 1.9151, Lge9 12.1448\n",
      "# 15717, T 6532.3, Ltr 0.1320, Lge4 1.6030, Lge9 5.5087\n",
      "# 15766, T 6552.6, Ltr 0.1886, Lge4 1.8834, Lge9 4.0206\n",
      "# 15813, T 6573.1, Ltr 0.2604, Lge4 0.7758, Lge9 3.9338\n",
      "# 15858, T 6593.1, Ltr 0.2123, Lge4 1.2685, Lge9 6.0187\n",
      "# 15906, T 6613.1, Ltr 0.0993, Lge4 0.7496, Lge9 4.7525\n",
      "# 15951, T 6633.5, Ltr 0.1285, Lge4 1.7360, Lge9 7.1588\n",
      "# 15996, T 6653.8, Ltr 0.2889, Lge4 1.0774, Lge9 6.9436\n",
      "# 16043, T 6674.0, Ltr 0.1241, Lge4 1.4404, Lge9 4.0169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b83a7396a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"loss_9\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_op_9_ge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m\"true_rollout_9\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrue_nodes_rollout_9_ge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;34m\"predicted_rollout_9\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_nodes_rollout_9_ge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     })\n\u001b[1;32m     38\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title Run training  { form-width: \"30%\" }\n",
    "\n",
    "# You can interrupt this cell's training loop at any time, and visualize the\n",
    "# intermediate results by running the next cell (below). You can then resume\n",
    "# training by simply executing this cell again.\n",
    "\n",
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 20\n",
    "\n",
    "print(\"# (iteration number), T (elapsed seconds), \"\n",
    "      \"Ltr (training 1-step loss), \"\n",
    "      \"Lge4 (test/generalization rollout loss for 4-mass strings), \"\n",
    "      \"Lge9 (test/generalization rollout loss for 9-mass strings)\")\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "  last_iteration = iteration\n",
    "  train_values = sess.run({\n",
    "      \"step\": step_op,\n",
    "      \"loss\": loss_op_tr,\n",
    "      \"input_graph\": input_graph_tr,\n",
    "      \"target_nodes\": target_nodes_tr,\n",
    "      \"outputs\": output_ops_tr\n",
    "  })\n",
    "  the_time = time.time()\n",
    "  elapsed_since_last_log = the_time - last_log_time\n",
    "  if elapsed_since_last_log > log_every_seconds:\n",
    "    last_log_time = the_time\n",
    "    test_values = sess.run({\n",
    "        \"loss_4\": loss_op_4_ge,\n",
    "        \"true_rollout_4\": true_nodes_rollout_4_ge,\n",
    "        \"predicted_rollout_4\": predicted_nodes_rollout_4_ge,\n",
    "        \"loss_9\": loss_op_9_ge,\n",
    "        \"true_rollout_9\": true_nodes_rollout_9_ge,\n",
    "        \"predicted_rollout_9\": predicted_nodes_rollout_9_ge\n",
    "    })\n",
    "    elapsed = time.time() - start_time\n",
    "    losses_tr.append(train_values[\"loss\"])\n",
    "    losses_4_ge.append(test_values[\"loss_4\"])\n",
    "    losses_9_ge.append(test_values[\"loss_9\"])\n",
    "    logged_iterations.append(iteration)\n",
    "    print(\"# {:05d}, T {:.1f}, Ltr {:.4f}, Lge4 {:.4f}, Lge9 {:.4f}\".format(\n",
    "        iteration, elapsed, train_values[\"loss\"], test_values[\"loss_4\"],\n",
    "        test_values[\"loss_9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "j1FgiIm-pmRq"
   },
   "outputs": [],
   "source": [
    "#@title Visualize loss curves  { form-width: \"30%\" }\n",
    "\n",
    "# This cell visualizes the results of training. You can visualize the\n",
    "# intermediate results by interrupting execution of the cell above, and running\n",
    "# this cell. You can then resume training by simply executing the above cell\n",
    "# again.\n",
    "\n",
    "def get_node_trajectories(rollout_array, batch_size):  # pylint: disable=redefined-outer-name\n",
    "  return np.split(rollout_array[..., :2], batch_size, axis=1)\n",
    "\n",
    "\n",
    "fig = plt.figure(1, figsize=(18, 3))\n",
    "fig.clf()\n",
    "x = np.array(logged_iterations)\n",
    "# Next-step Loss.\n",
    "y = losses_tr\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.plot(x, y, \"k\")\n",
    "ax.set_title(\"Next step loss\")\n",
    "# Rollout 5 loss.\n",
    "y = losses_4_ge\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.plot(x, y, \"k\")\n",
    "ax.set_title(\"Rollout loss: 5-mass string\")\n",
    "# Rollout 9 loss.\n",
    "y = losses_9_ge\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.plot(x, y, \"k\")\n",
    "ax.set_title(\"Rollout loss: 9-mass string\")\n",
    "\n",
    "# Visualize trajectories.\n",
    "true_rollouts_4 = get_node_trajectories(test_values[\"true_rollout_4\"],\n",
    "                                        batch_size_ge)\n",
    "predicted_rollouts_4 = get_node_trajectories(test_values[\"predicted_rollout_4\"],\n",
    "                                             batch_size_ge)\n",
    "true_rollouts_9 = get_node_trajectories(test_values[\"true_rollout_9\"],\n",
    "                                        batch_size_ge)\n",
    "predicted_rollouts_9 = get_node_trajectories(test_values[\"predicted_rollout_9\"],\n",
    "                                             batch_size_ge)\n",
    "\n",
    "true_rollouts = true_rollouts_4\n",
    "predicted_rollouts = predicted_rollouts_4\n",
    "true_rollouts = true_rollouts_9\n",
    "predicted_rollouts = predicted_rollouts_9\n",
    "\n",
    "num_graphs = len(true_rollouts)\n",
    "num_time_steps = true_rollouts[0].shape[0]\n",
    "\n",
    "# Plot state sequences.\n",
    "max_graphs_to_plot = 1\n",
    "num_graphs_to_plot = min(num_graphs, max_graphs_to_plot)\n",
    "num_steps_to_plot = 24\n",
    "max_time_step = num_time_steps - 1\n",
    "step_indices = np.floor(np.linspace(0, max_time_step,\n",
    "                                    num_steps_to_plot)).astype(int).tolist()\n",
    "w = 6\n",
    "h = int(np.ceil(num_steps_to_plot / w))\n",
    "fig = plt.figure(101, figsize=(18, 8))\n",
    "fig.clf()\n",
    "for i, (true_rollout, predicted_rollout) in enumerate(\n",
    "    zip(true_rollouts, predicted_rollouts)):\n",
    "  xys = np.hstack([predicted_rollout, true_rollout]).reshape([-1, 2])\n",
    "  xs = xys[:, 0]\n",
    "  ys = xys[:, 1]\n",
    "  b = 0.05\n",
    "  xmin = xs.min() - b * xs.ptp()\n",
    "  xmax = xs.max() + b * xs.ptp()\n",
    "  ymin = ys.min() - b * ys.ptp()\n",
    "  ymax = ys.max() + b * ys.ptp()\n",
    "  if i >= num_graphs_to_plot:\n",
    "    break\n",
    "  for j, step_index in enumerate(step_indices):\n",
    "    iax = i * w + j + 1\n",
    "    ax = fig.add_subplot(h, w, iax)\n",
    "    ax.plot(\n",
    "        true_rollout[step_index, :, 0],\n",
    "        true_rollout[step_index, :, 1],\n",
    "        \"k\",\n",
    "        label=\"True\")\n",
    "    ax.plot(\n",
    "        predicted_rollout[step_index, :, 0],\n",
    "        predicted_rollout[step_index, :, 1],\n",
    "        \"r\",\n",
    "        label=\"Predicted\")\n",
    "    ax.set_title(\"Example {:02d}: frame {:03d}\".format(i, step_index))\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if j == 0:\n",
    "      ax.legend(loc=3)\n",
    "\n",
    "# Plot x and y trajectories over time.\n",
    "max_graphs_to_plot = 3\n",
    "num_graphs_to_plot = min(len(true_rollouts), max_graphs_to_plot)\n",
    "w = 2\n",
    "h = num_graphs_to_plot\n",
    "fig = plt.figure(102, figsize=(18, 12))\n",
    "fig.clf()\n",
    "for i, (true_rollout, predicted_rollout) in enumerate(\n",
    "    zip(true_rollouts, predicted_rollouts)):\n",
    "  if i >= num_graphs_to_plot:\n",
    "    break\n",
    "  t = np.arange(num_time_steps)\n",
    "  for j in range(2):\n",
    "    coord_string = \"x\" if j == 0 else \"y\"\n",
    "    iax = i * 2 + j + 1\n",
    "    ax = fig.add_subplot(h, w, iax)\n",
    "    ax.plot(t, true_rollout[..., j], \"k\", label=\"True\")\n",
    "    ax.plot(t, predicted_rollout[..., j], \"r\", label=\"Predicted\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"{} coordinate\".format(coord_string))\n",
    "    ax.set_title(\"Example {:02d}: Predicted vs actual coords over time\".format(\n",
    "        i))\n",
    "    ax.set_frame_on(False)\n",
    "    if i == 0 and j == 1:\n",
    "      handles, labels = ax.get_legend_handles_labels()\n",
    "      unique_labels = []\n",
    "      unique_handles = []\n",
    "      for i, (handle, label) in enumerate(zip(handles, labels)):  # pylint: disable=redefined-outer-name\n",
    "        if label not in unique_labels:\n",
    "          unique_labels.append(label)\n",
    "          unique_handles.append(handle)\n",
    "      ax.legend(unique_handles, unique_labels, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/dm_python:dm_notebook",
    "kind": "private"
   },
   "name": "physics.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
